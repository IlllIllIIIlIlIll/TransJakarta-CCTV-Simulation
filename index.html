<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no" />
<title>üëÄ CrowdEase ‚Äî Live Person Counter (YOLOv8n ONNX)</title>
<style>
  :root {
    color-scheme: dark;
    --bg:#0b0c0f; --panel:#151821; --muted:#9aa3b2; --accent:#22c55e; --warn:#f97316;
    --border:#222633; --text:#e5e7eb; --chip:#111319;
  }
  body{margin:0;font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Ubuntu,"Helvetica Neue",Arial;
       background:var(--bg);color:var(--text);display:flex;justify-content:center}
  main{max-width:1080px;width:100%;padding:16px 16px 48px}
  .card{background:var(--panel);border:1px solid var(--border);border-radius:14px;padding:14px 16px;margin-bottom:16px}
  h1{margin:6px 0 10px;font-size:1.5rem;line-height:1.2}
  .row{display:flex;gap:10px;flex-wrap:wrap;align-items:center}
  button,select,input[type=range]{background:#202433;border:1px solid var(--border);color:var(--text);
    border-radius:10px;height:38px;padding:0 12px;font-size:.95rem}
  button:disabled{opacity:.5}
  .ok{display:inline-flex;align-items:center;gap:6px;font-size:.9rem}
  .dot{width:10px;height:10px;border-radius:50%}
  .green{background:#22c55e}.red{background:#ef4444}.yellow{background:#f59e0b}
  canvas,video{display:block;width:100%;height:auto;border-radius:12px;border:1px solid var(--border);background:#000}
  .badge{position:absolute;left:16px;top:16px;background:#10131c;border:1px solid var(--border);
    padding:6px 10px;border-radius:10px;font-weight:700}
  .modeltag{position:absolute;right:16px;top:16px;background:#10131c;border:1px solid var(--border);
    padding:6px 10px;border-radius:10px;font-size:.9rem;color:var(--muted)}
  .stack{position:relative}
  .console{height:220px;white-space:pre;overflow:auto;background:#0e1016;border-radius:12px;border:1px solid var(--border);
    padding:10px;font-family:ui-monospace,Consolas,monospace;font-size:.88rem}
  .grow{flex:1}
  .label{color:var(--muted);font-size:.9rem;margin-right:6px}
  .slider{display:flex;align-items:center;gap:8px}
  .chip{background:var(--chip);border:1px solid var(--border);padding:6px 10px;border-radius:10px;color:var(--muted);font-size:.9rem}
</style>
<!-- onnxruntime-web (WebGPU/WebGL/WASM) -->
<script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.20.0/dist/ort.min.js"></script>
</head>
<body>
<main>
  <div class="card">
    <h1>üëÄ CrowdEase ‚Äî Live Person Counter</h1>
    <div class="row" style="margin-bottom:10px">
      <button id="startBtn">‚ñ∂Ô∏è Start</button>
      <button id="stopBtn" disabled>‚èπÔ∏è Stop</button>
      <select id="camSel" title="Camera"></select>
      <select id="facingSel" title="Facing">
        <option value="auto">Auto (by facing)</option>
        <option value="environment" selected>Back camera</option>
        <option value="user">Front camera</option>
      </select>
      <div class="slider">
        <span class="label">Threshold:</span>
        <input id="thr" type="range" min="0.10" max="0.80" step="0.01" value="0.35">
        <span id="thrVal" class="chip">0.35</span>
      </div>
      <div class="ok"><span id="modelDot" class="dot red"></span> <span id="modelMsg">loading‚Ä¶</span></div>
      <div class="grow"></div>
      <span class="chip">YOLOv8n (person)</span>
    </div>
    <div class="stack">
      <canvas id="view"></canvas>
      <div class="badge" id="countBadge">People: 0</div>
      <div class="modeltag" id="modelTag">Model: YOLOv8n (ONNX)</div>
      <video id="video" playsinline muted style="display:none"></video>
      <canvas id="infer" style="display:none"></canvas>
    </div>
  </div>

  <div class="card">
    <div class="row" style="justify-content:space-between;align-items:center;margin-bottom:8px">
      <div class="label">Console</div>
      <div class="chip">Open DevTools ‚Üí Console for the same logs.</div>
    </div>
    <div id="log" class="console"></div>
    <div class="label" style="margin-top:8px">Works fully in the browser (static on Vercel). No Python, no servers.</div>
  </div>
</main>

<script>
/* --------------------- configuration --------------------- */
const MODEL_INPUT = 640;                   // YOLOv8n input size (square)
const MAX_DETS   = 200;                    // max boxes after prefilter
const NMS_IOU    = 0.45;                   // NMS IOU threshold
const EMA_ALPHA  = 0.35;                   // smoothing for count
// 1st tries local file (put it in /models), then CDN fallback (best-effort)
const MODEL_URLS = [
  "/models/yolov8n.onnx",
  "https://huggingface.co/onnx-community/ultralytics/resolve/main/yolov8n.onnx?download=true"
];

/* --------------------- logging helpers ------------------- */
const logEl = document.getElementById('log');
function log(...a){ const s = a.map(x => typeof x==='string'?x:JSON.stringify(x)).join(' ');
  console.log('[INFO]',...a); logEl.textContent += `[INFO] ${s}\n`; logEl.scrollTop = logEl.scrollHeight; }
function warn(...a){ console.warn('[WARN]',...a); logEl.textContent += `[WARN] ${a.join(' ')}\n`; }
function err(...a){ console.error('[ERROR]',...a); logEl.textContent += `[ERROR] ${a.join(' ')}\n`; }

/* --------------------- UI elements ----------------------- */
const startBtn = document.getElementById('startBtn');
const stopBtn  = document.getElementById('stopBtn');
const camSel   = document.getElementById('camSel');
const facingSel= document.getElementById('facingSel');
const thrEl    = document.getElementById('thr');
const thrVal   = document.getElementById('thrVal');
const modelDot = document.getElementById('modelDot');
const modelMsg = document.getElementById('modelMsg');
const countBadge = document.getElementById('countBadge');
const view = document.getElementById('view');   const vctx = view.getContext('2d');
const video= document.getElementById('video');
const infer = document.getElementById('infer'); const ictx = infer.getContext('2d',{willReadFrequently:true});
thrEl.addEventListener('input', ()=> thrVal.textContent = (+thrEl.value).toFixed(2));

/* --------------------- device selection ------------------ */
async function listCams(){
  camSel.innerHTML = "";
  try{
    const devices = (await navigator.mediaDevices.enumerateDevices())
      .filter(d => d.kind === 'videoinput');
    devices.forEach((d,i)=>{
      const o = document.createElement('option');
      o.value = d.deviceId; o.textContent = d.label || `Camera ${i+1}`;
      camSel.appendChild(o);
    });
    if(!devices.length){ warn("No cameras found."); }
  }catch(e){ warn("enumerateDevices failed", e); }
}

/* --------------------- onnxruntime setup ----------------- */
let session = null;
ort.env.wasm.numThreads = 1;
ort.env.wasm.wasmPaths = "https://cdn.jsdelivr.net/npm/onnxruntime-web@1.20.0/dist/"; // for WASM fallback

async function loadModel(){
  modelDot.className = "dot yellow"; modelMsg.textContent = "loading model‚Ä¶";
  for(const url of MODEL_URLS){
    try{
      log("loading ONNX model‚Ä¶", url);
      session = await ort.InferenceSession.create(url, {
        executionProviders: ['webgpu','webgl','wasm'] // pick the best available
      });
      modelDot.className = "dot green"; modelMsg.textContent = "model OK";
      log("model ready using EPs:", session.executionProvider);
      return;
    }catch(e){
      warn("model load failed:", e?.message || e);
    }
  }
  modelDot.className = "dot red"; modelMsg.textContent = "model failed";
  throw new Error("All model URLs failed to load.");
}

/* --------------------- camera pipeline ------------------- */
let stream=null, running=false, ema=0;
function stopCam(){
  running=false;
  startBtn.disabled=false; stopBtn.disabled=true;
  if(stream){stream.getTracks().forEach(t=>t.stop()); stream=null;}
}
async function startCam(){
  stopCam();
  const facing = facingSel.value; // user | environment | auto
  const devId  = camSel.value || undefined;
  const constraints = {
    audio:false,
    video: devId ? {deviceId: {exact: devId}, width:{ideal:1280},height:{ideal:720}}
                 : {facingMode: facing==='auto'? undefined : facing, width:{ideal:1280},height:{ideal:720}}
  };
  log("requesting camera‚Ä¶", JSON.stringify(constraints));
  stream = await navigator.mediaDevices.getUserMedia(constraints);
  video.srcObject = stream;
  await video.play();

  // fit canvas to stream
  view.width = video.videoWidth;  view.height = video.videoHeight;
  log("camera started. size:", view.height, "x", view.width);

  running=true; startBtn.disabled=true; stopBtn.disabled=false;
  ema = 0;
  loop();
}

/* --------------------- math helpers ---------------------- */
function sigmoid(x){ return 1/(1+Math.exp(-x)); }
function iou(boxA, boxB){ // [x1,y1,x2,y2]
  const x1 = Math.max(boxA[0], boxB[0]);
  const y1 = Math.max(boxA[1], boxB[1]);
  const x2 = Math.min(boxA[2], boxB[2]);
  const y2 = Math.min(boxA[3], boxB[3]);
  const inter = Math.max(0, x2-x1) * Math.max(0, y2-y1);
  const a = (boxA[2]-boxA[0])*(boxA[3]-boxA[1]);
  const b = (boxB[2]-boxB[0])*(boxB[3]-boxB[1]);
  return inter / (a + b - inter + 1e-9);
}
function nms(boxes, scores, iouTh=NMS_IOU, topK=300){
  const idx = scores.map((s,i)=>[s,i]).sort((a,b)=>b[0]-a[0]).map(x=>x[1]);
  const keep=[];
  for(const i of idx){
    if(keep.length>=topK) break;
    let drop=false;
    for(const j of keep){ if(iou(boxes[i], boxes[j])>iouTh){ drop=true; break; } }
    if(!drop) keep.push(i);
  }
  return keep;
}

/* --------------------- letterbox resize ------------------ */
function letterbox(srcW, srcH, dst=MODEL_INPUT){
  const r = Math.min(dst/srcW, dst/srcH);
  const newW = Math.round(srcW*r), newH = Math.round(srcH*r);
  const padW = dst - newW, padH = dst - newH;
  return {r, newW, newH, padLeft:Math.floor(padW/2), padTop:Math.floor(padH/2)};
}

/* --------------------- main loop ------------------------- */
async function loop(){
  if(!running) return;
  const t0 = performance.now();

  // 1) prepare model input with letterbox
  const L = letterbox(video.videoWidth, video.videoHeight, MODEL_INPUT);
  infer.width = MODEL_INPUT; infer.height = MODEL_INPUT;
  ictx.fillStyle = "#000"; ictx.fillRect(0,0,MODEL_INPUT,MODEL_INPUT);
  ictx.drawImage(video, 0,0, video.videoWidth, video.videoHeight,
                 L.padLeft, L.padTop, L.newW, L.newH);
  // NHWC uint8 -> NCHW float32 / 0..1
  const imgData = ictx.getImageData(0,0,MODEL_INPUT,MODEL_INPUT);
  const data = imgData.data;
  const chw = new Float32Array(3*MODEL_INPUT*MODEL_INPUT);
  let p=0, r=0, g=MODEL_INPUT*MODEL_INPUT, b=2*g;
  for(let i=0;i<data.length;i+=4){
    const R=data[i]/255, G=data[i+1]/255, B=data[i+2]/255;
    chw[p++] = R; chw[g++] = G; chw[b++] = B;
  }
  const input = new ort.Tensor('float32', chw, [1,3,MODEL_INPUT,MODEL_INPUT]);

  // 2) run model
  const out = await session.run({[session.inputNames[0]]: input});
  const raw = out[session.outputNames[0]];
  // Expect shape [1,84,8400] or [1,8400,84]
  let arr = raw.data, shape = raw.dims;
  let stride, nPred, nc;
  let get = (i,j)=> arr[i*stride + j];
  if(shape[1]===84){ // [1,84,8400]
    nc = shape[1]-5; nPred=shape[2]; stride = nPred;
    get = (i,j)=> arr[j + i*stride]; // i=row (0..83), j=col (0..nPred-1)
  }else{             // [1,8400,84]
    nPred = shape[1]; nc = shape[2]-5; stride = shape[2];
    get = (i,j)=> arr[i*stride + j]; // i=row (0..nPred-1), j=col (0..83)
  }

  // 3) filter to 'person' only, build boxes/scores
  const confTh = parseFloat(thrEl.value || "0.35");
  const boxes=[], scores=[];
  // person class index in COCO = 0
  if(shape[1]===84){
    for(let j=0;j<nPred;j++){
      const x=get(0,j), y=get(1,j), w=get(2,j), h=get(3,j);
      const obj=sigmoid(get(4,j));
      const cls=sigmoid(get(5,j)); // class 0
      const score = obj*cls;
      if(score<confTh) continue;
      const x1=(x-w/2), y1=(y-h/2), x2=(x+w/2), y2=(y+h/2);
      boxes.push([x1,y1,x2,y2]); scores.push(score);
      if(boxes.length>=MAX_DETS) break;
    }
  }else{
    for(let i=0;i<nPred;i++){
      const x=get(i,0), y=get(i,1), w=get(i,2), h=get(i,3);
      const obj=sigmoid(get(i,4));
      const cls=sigmoid(get(i,5)); // class 0
      const score = obj*cls;
      if(score<confTh) continue;
      const x1=(x-w/2), y1=(y-h/2), x2=(x+w/2), y2=(y+h/2);
      boxes.push([x1,y1,x2,y2]); scores.push(score);
      if(boxes.length>=MAX_DETS) break;
    }
  }

  // 4) NMS + map back to original size (undo letterbox scale)
  const keep = nms(boxes, scores, NMS_IOU, MAX_DETS);
  const picked = keep.map(i => ({ box:boxes[i], score:scores[i] }));
  const scale = 1 / L.r;
  const mapped = picked.map(p=>{
    let [x1,y1,x2,y2] = p.box;
    x1 = (x1 - L.padLeft) * scale;
    x2 = (x2 - L.padLeft) * scale;
    y1 = (y1 - L.padTop ) * scale;
    y2 = (y2 - L.padTop ) * scale;
    // clip:
    x1=Math.max(0,Math.min(view.width ,x1)); x2=Math.max(0,Math.min(view.width ,x2));
    y1=Math.max(0,Math.min(view.height,y1)); y2=Math.max(0,Math.min(view.height,y2));
    return {x1,y1,x2,y2, score:p.score};
  });

  // 5) draw
  vctx.drawImage(video,0,0,view.width,view.height);
  vctx.lineWidth = 2; vctx.strokeStyle="#22c55e"; vctx.font="14px ui-sans-serif";
  mapped.forEach(b=>{
    vctx.strokeRect(b.x1,b.y1,b.x2-b.x1,b.y2-b.y1);
    const s = Math.round(b.score*100);
    const w = vctx.measureText(`${s}%`).width + 8;
    vctx.fillStyle="rgba(0,0,0,.55)"; vctx.fillRect(b.x1,b.y1-18,w,18);
    vctx.fillStyle="#e5e7eb"; vctx.fillText(`${s}%`, b.x1+4, b.y1-5);
  });

  // 6) smooth count
  const rawCount = mapped.length;
  ema = EMA_ALPHA*rawCount + (1-EMA_ALPHA)*ema;
  const smoothed = Math.round(ema);
  countBadge.textContent = `People: ${smoothed}`;

  const dt = (performance.now()-t0)/1000;
  if((Math.random()<0.05)) log(`[RESULT] People=${smoothed} thr=${confTh.toFixed(2)} fps‚âà${(1/dt).toFixed(1)}`);

  if(running) requestAnimationFrame(loop);
}

/* --------------------- boot ------------------------------ */
startBtn.onclick = async ()=>{
  try{
    if(!session) await loadModel();
    await listCams();
    await startCam();
  }catch(e){ err("start failed:", e); }
};
stopBtn.onclick = ()=> stopCam();
facingSel.onchange = ()=> { if(running) startCam(); };
camSel.onchange    = ()=> { if(running) startCam(); };
window.addEventListener('load', listCams);
</script>
</body>
</html>
